{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to ingest the MNIST dataset and process it from raw to interim to processed stages.\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load the raw MNIST dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(raw_train_images, raw_train_labels), (raw_test_images, raw_test_labels) = mnist.load_data()\n",
    "\n",
    "# Interim Processing: Normalize pixel values to be between 0 and 1\n",
    "interim_train_images = raw_train_images / 255.0\n",
    "interim_test_images = raw_test_images / 255.0\n",
    "\n",
    "# Processed Data: Flatten the images and scale the pixel values\n",
    "scaler = MinMaxScaler()\n",
    "# Flatten the images\n",
    "processed_train_images = interim_train_images.reshape((-1, 28*28))\n",
    "processed_test_images = interim_test_images.reshape((-1, 28*28))\n",
    "# Scale the pixel values\n",
    "processed_train_images = scaler.fit_transform(processed_train_images)\n",
    "processed_test_images = scaler.transform(processed_test_images)\n",
    "\n",
    "# Convert the datasets to pandas DataFrames for further analysis or storage\n",
    "train_df = pd.DataFrame(processed_train_images)\n",
    "train_df['label'] = raw_train_labels\n",
    "test_df = pd.DataFrame(processed_test_images)\n",
    "test_df['label'] = raw_test_labels\n",
    "\n",
    "# Save the processed data to CSV files\n",
    "train_df.to_csv('data/processed/mnist_train_processed.csv', index=False)\n",
    "test_df.to_csv('data/processed/mnist_test_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load raw data\n",
    "(mnist_train_images, mnist_train_labels), (mnist_test_images, mnist_test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize (interim processing)\n",
    "mnist_train_images_norm = mnist_train_images / 255.0\n",
    "mnist_test_images_norm = mnist_test_images / 255.0\n",
    "\n",
    "# Flatten and scale (processed data)\n",
    "scaler = MinMaxScaler()\n",
    "mnist_train_images_flat = scaler.fit_transform(mnist_train_images_norm.reshape(-1, 28*28))\n",
    "mnist_test_images_flat = scaler.transform(mnist_test_images_norm.reshape(-1, 28*28))\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(mnist_train_images_flat, columns=[f'pixel_{i}' for i in range(784)])\n",
    "train_df['label'] = mnist_train_labels\n",
    "\n",
    "test_df = pd.DataFrame(mnist_test_images_flat, columns=[f'pixel_{i}' for i in range(784)])\n",
    "test_df['label'] = mnist_test_labels\n",
    "\n",
    "# Save to CSV\n",
    "train_df.to_csv('mnist_train_processed.csv', index=False)\n",
    "test_df.to_csv('mnist_test_processed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import os\n",
    "\n",
    "# Function to load and save the raw MNIST dataset\n",
    "def load_and_save_raw_mnist():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # Saving raw data\n",
    "    np.save(os.path.join('data', 'raw', 'x_train_raw.npy'), x_train)\n",
    "    np.save(os.path.join('data', 'raw', 'y_train_raw.npy'), y_train)\n",
    "    np.save(os.path.join('data', 'raw', 'x_test_raw.npy'), x_test)\n",
    "    np.save(os.path.join('data', 'raw', 'y_test_raw.npy'), y_test)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# Function to preprocess data to an interim stage\n",
    "def preprocess_to_interim(x_train, x_test):\n",
    "    # Normalizing the images to the range of [0, 1]\n",
    "    x_train_interim = x_train.astype(\"float32\") / 255\n",
    "    x_test_interim = x_test.astype(\"float32\") / 255\n",
    "\n",
    "    # Saving interim data\n",
    "    np.save(os.path.join('data', 'interim', 'x_train_interim.npy'), x_train_interim)\n",
    "    np.save(os.path.join('data', 'interim', 'x_test_interim.npy'), x_test_interim)\n",
    "\n",
    "    return x_train_interim, x_test_interim\n",
    "\n",
    "# Function to further process data to the final processed stage\n",
    "def process_to_final(x_train_interim, y_train, x_test_interim, y_test):\n",
    "    # Reshaping the data to fit model input\n",
    "    x_train_processed = x_train_interim.reshape((-1, 28, 28, 1))\n",
    "    x_test_processed = x_test_interim.reshape((-1, 28, 28, 1))\n",
    "\n",
    "    # Saving processed data\n",
    "    np.save(os.path.join('data', 'processed', 'x_train_processed.npy'), x_train_processed)\n",
    "    np.save(os.path.join('data', 'processed', 'y_train_processed.npy'), y_train)\n",
    "    np.save(os.path.join('data', 'processed', 'x_test_processed.npy'), x_test_processed)\n",
    "    np.save(os.path.join('data', 'processed', 'y_test_processed.npy'), y_test)\n",
    "\n",
    "    return x_train_processed, x_test_processed\n",
    "\n",
    "# Main function to run the data processing pipeline\n",
    "def main():\n",
    "    # Ensure the necessary directories exist\n",
    "    os.makedirs(os.path.join('data', 'raw'), exist_ok=True)\n",
    "    os.makedirs(os.path.join('data', 'interim'), exist_ok=True)\n",
    "    os.makedirs(os.path.join('data', 'processed'), exist_ok=True)\n",
    "\n",
    "    # Load and save raw data\n",
    "    x_train, y_train, x_test, y_test = load_and_save_raw_mnist()\n",
    "\n",
    "    # Preprocess data to interim stage\n",
    "    x_train_interim, x_test_interim = preprocess_to_interim(x_train, x_test)\n",
    "\n",
    "    # Process data to final stage\n",
    "    x_train_processed, x_test_processed = process_to_final(x_train_interim, y_train, x_test_interim, y_test)\n",
    "\n",
    "    print(\"Data processing complete. Data saved in 'data' directory.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
